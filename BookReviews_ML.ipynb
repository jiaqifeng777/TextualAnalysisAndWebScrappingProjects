{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"/Users/Judy-Ccino412/Desktop/cse158/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dataDir + \"goodreads_reviews_comics_graphic.json.gz\"\n",
    "f = gzip.open(path, 'rt', encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for l in f:\n",
    "    d = json.loads(l)\n",
    "    data.append(d)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dc3763cdb9b2cae805882878eebb6a32',\n",
       " '18471619',\n",
       " '66b2ba840f9bd36d6d27f46136fe4772',\n",
       " 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['user_id'], data[0]['book_id'], data[0]['review_id'], data[0]['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a few utility data structures\n",
    "usersPerItem = defaultdict(set) # Maps an item to the users who rated it\n",
    "itemsPerUser = defaultdict(set) # Maps a user to the items that they rated\n",
    "reviewId = {}\n",
    "ratingDict = {} # To retrieve a rating for a specific user/item pair\n",
    "\n",
    "for d in data:\n",
    "    user,item = d['user_id'], d['book_id']\n",
    "    usersPerItem[item].add(user)\n",
    "    itemsPerUser[user].add(item)\n",
    "    ratingDict[(user,item)] = d['rating']\n",
    "    reviewId[item] = d['review_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract per-user and per-item averages (useful later for rating prediction)\n",
    "userAverages = {}\n",
    "itemAverages = {}\n",
    "\n",
    "for u in itemsPerUser:\n",
    "    rs = [ratingDict[(u,i)] for i in itemsPerUser[u]]\n",
    "    userAverages[u] = sum(rs) / len(rs)\n",
    "    \n",
    "for i in usersPerItem:\n",
    "    rs = [ratingDict[(u,i)] for u in usersPerItem[i]]\n",
    "    itemAverages[i] = sum(rs) / len(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaccard Similarity\n",
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilarItem(i, N):\n",
    "    similarities = []\n",
    "    users = usersPerItem[i]\n",
    "    for i2 in usersPerItem:\n",
    "        if i2 == i: \n",
    "            continue\n",
    "        sim = Jaccard(users, usersPerItem[i2])  # ie. sim = common users / union users\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(key=lambda tup: (-tup[0], tup[1]))\n",
    "    return similarities[:N]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18471619'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = data[0]['book_id']\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.16666666666666666, '25334626'),\n",
       " (0.14285714285714285, '25659811'),\n",
       " (0.13793103448275862, '18369278'),\n",
       " (0.13157894736842105, '18430205'),\n",
       " (0.12903225806451613, '20299669'),\n",
       " (0.125, '17995154'),\n",
       " (0.12121212121212122, '18853527'),\n",
       " (0.12121212121212122, '23093378'),\n",
       " (0.12121212121212122, '23241671'),\n",
       " (0.11764705882352941, '18734070')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1 answer\n",
    "mostSimilarItem(query, 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Choosing the N items most similar to the user’s favorite (i.e., highest rated) item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dc3763cdb9b2cae805882878eebb6a32'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = data[0]['user_id']\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'18471619'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All items that User u has\n",
    "i_of_u = itemsPerUser[u]\n",
    "i_of_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find favorite item of User u\n",
    "def fav_i_of_user(u, all_items_of_u):\n",
    "    ratings = [-1]\n",
    "    for i in sorted(all_items_of_u):\n",
    "        i_rating = ratingDict[(u, i)]\n",
    "        if i_rating > max(ratings):\n",
    "            ratings.append(i_rating)\n",
    "            fav_i = i\n",
    "    return fav_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18471619'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fav_i_of_u = fav_i_of_user(u, i_of_u)\n",
    "fav_i_of_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.16666666666666666, '25334626'),\n",
       " (0.14285714285714285, '25659811'),\n",
       " (0.13793103448275862, '18369278'),\n",
       " (0.13157894736842105, '18430205'),\n",
       " (0.12903225806451613, '20299669'),\n",
       " (0.125, '17995154'),\n",
       " (0.12121212121212122, '18853527'),\n",
       " (0.12121212121212122, '23093378'),\n",
       " (0.12121212121212122, '23241671'),\n",
       " (0.11764705882352941, '18734070')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2(a) answer\n",
    "# 10 items most similar to the User u’s favorite\n",
    "mostSimilarItem(fav_i_of_u, 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Finding the N most similar users, and recommending each of their their favorite (highest rated) items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilarUser(u, N):\n",
    "    similarities = []\n",
    "    items = itemsPerUser[u]\n",
    "    candidateUsers = set()\n",
    "    for i in items:\n",
    "        candidateUsers = candidateUsers.union(usersPerItem[i])\n",
    "    for u2 in candidateUsers:\n",
    "        if u2 == u: \n",
    "            continue\n",
    "        sim = Jaccard(items, itemsPerUser[u2])  # ie. sim = common items / union items\n",
    "        similarities.append((sim,u2))\n",
    "    similarities.sort(key=lambda tup: (-tup[0], tup[1]))\n",
    "    return similarities[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, '4ae069d704b11bdf12c25fe640f75ff0'),\n",
       " (0.3333333333333333, '6470c7f5e3468ba34e9fe628960fbbf1'),\n",
       " (0.25, '6497ca91df3c182006874c96a8530b37'),\n",
       " (0.2, '033cf640dfa6f85eb146c39787289628'),\n",
       " (0.14285714285714285, '5510684ab6c18f2dd493787e66b2722c'),\n",
       " (0.05555555555555555, '17f73ea38e97307935c0d3b6ca987b53'),\n",
       " (0.030303030303030304, 'a39b4249d201ef5ce5ea553bdd013e66'),\n",
       " (0.023809523809523808, '42519f961f79b61701bda60787b031cf'),\n",
       " (0.02040816326530612, '65a7975989734fc6e18b7d2bd2bcb49f'),\n",
       " (0.014925373134328358, '0fafb6f0843124383f4e2c5a2090fb09')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 most similar users to User u with the scores (doesn't skip users)\n",
    "top_ten = mostSimilarUser(u, 10)\n",
    "top_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4ae069d704b11bdf12c25fe640f75ff0',\n",
       " '6470c7f5e3468ba34e9fe628960fbbf1',\n",
       " '6497ca91df3c182006874c96a8530b37',\n",
       " '033cf640dfa6f85eb146c39787289628',\n",
       " '5510684ab6c18f2dd493787e66b2722c',\n",
       " '17f73ea38e97307935c0d3b6ca987b53',\n",
       " 'a39b4249d201ef5ce5ea553bdd013e66',\n",
       " '42519f961f79b61701bda60787b031cf',\n",
       " '65a7975989734fc6e18b7d2bd2bcb49f',\n",
       " '0fafb6f0843124383f4e2c5a2090fb09']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the 10 most similar users to User u (doesn't skip users)\n",
    "ten_similar_users = [tup[1] for tup in mostSimilarUser(u, 10)]\n",
    "ten_similar_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all items of the similar uses\n",
    "all_items_of_sus = {}\n",
    "for su in ten_similar_users:\n",
    "    all_items_of_su = sorted(itemsPerUser[su])\n",
    "    all_items_of_sus[su] = (all_items_of_su)\n",
    "\n",
    "#all_items_of_sus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy: Skip the current similar user ONLY WHEN all the items of this similar user are purchased by User u, OTHERWISE, move to the NEXT FAVORITE ITEM of this similar user instead of skipping this similar user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend an item for User u based on the fav item of a similar user\n",
    "def recommend_for_u_with_su(su, all_items_of_su, i_of_u):\n",
    "    if len(all_items_of_su) == 0:\n",
    "        #print('no item satisfied: ' + su)\n",
    "        return\n",
    "    \n",
    "    # get the favorite item of the current similar user su\n",
    "    fav_i_of_su = fav_i_of_user(su, all_items_of_su)\n",
    "    #print(fav_i_of_su)\n",
    "    \n",
    "    # if this item is not purchased by User u, recommend it\n",
    "    if fav_i_of_su not in i_of_u:\n",
    "        #print(fav_i_of_su)\n",
    "        recommend_i = fav_i_of_su\n",
    "        return recommend_i  \n",
    "    \n",
    "    # if this item is purchased by User u, recommend the next favorite item of su\n",
    "    all_items_of_su = all_items_of_su[1:] \n",
    "    recommend_i = recommend_for_u_with_su(su, all_items_of_su, i_of_u)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10767466',\n",
       " '5805',\n",
       " '17570797',\n",
       " '15704307',\n",
       " '10138607',\n",
       " '12434747',\n",
       " '17995248',\n",
       " '10105459',\n",
       " '10997645',\n",
       " '10361139']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommend for User u \n",
    "recommend_items = []\n",
    "scores = []\n",
    "for su_i in range(len(ten_similar_users)):\n",
    "    su = ten_similar_users[su_i]\n",
    "    #print(su)\n",
    "    all_items_of_su = sorted(all_items_of_sus[su])\n",
    "    recommend_i = recommend_for_u_with_su(su, all_items_of_su, i_of_u)\n",
    "    \n",
    "    # if the similar user still has items that User u hasn't purchase, continue the recommendations\n",
    "    if recommend_i is not None:\n",
    "        recommend_items.append(recommend_i)\n",
    "        score = [i[0] for i in top_ten if i[1] == su]\n",
    "        scores.append(score)\n",
    "        all_items_of_sus[su].remove(recommend_i)\n",
    "        all_items_of_sus.update({su : all_items_of_sus[su]})\n",
    "        \n",
    "    # if the item is purchased by User u, SKIP THIS ITEM and\n",
    "    # move to the next similar user ONLY IF all the items of the similar user is purchase by User u\n",
    "    else:\n",
    "        su_next = ten_similar_users[su_i + 1]\n",
    "        all_items_of_su_next = sorted(all_items_of_sus[su_next])\n",
    "        recommend_i = recommend_for_u_with_su(su_next, all_items_of_su_next, i_of_u)\n",
    "        recommend_items.append(recommend_i)\n",
    "        score = [i[0] for i in top_ten if i[1] == su_next]\n",
    "        scores.append(score)\n",
    "        all_items_of_sus[su_next].remove(recommend_i)\n",
    "        all_items_of_sus.update({su_next : all_items_of_sus[su_next]})\n",
    "        \n",
    "    # recommend 10 items\n",
    "    if len(recommend_items) == 10:\n",
    "        break\n",
    "        \n",
    "recommend_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = [score[0] for score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3333333333333333, '10767466'),\n",
       " (0.3333333333333333, '5805'),\n",
       " (0.25, '17570797'),\n",
       " (0.2, '15704307'),\n",
       " (0.14285714285714285, '10138607'),\n",
       " (0.05555555555555555, '12434747'),\n",
       " (0.030303030303030304, '17995248'),\n",
       " (0.023809523809523808, '10105459'),\n",
       " (0.02040816326530612, '10997645'),\n",
       " (0.014925373134328358, '10361139')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2(b) answer \n",
    "[(s, i) for s,i in zip(score, recommend_items)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18471619'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1 = data[0]['book_id']\n",
    "i1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Pearson similarity with denominator only in terms of shared items (i.e., Ui ∩ Uj ) in the denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pearson1(i1, i2):\n",
    "    # Between two items\n",
    "    iBar1 = itemAverages[i1]    # avg rating of i1\n",
    "    iBar2 = itemAverages[i2]    # avg rating of i2\n",
    "    # intersection of users that have rated items i and j\n",
    "    inter = usersPerItem[i1].intersection(usersPerItem[i2])\n",
    "    numer = 0\n",
    "    denom1 = 0\n",
    "    denom2 = 0\n",
    "    \n",
    "    # numerator is the intersection of users\n",
    "    for u in inter:\n",
    "        numer += (ratingDict[(u,i1)] - iBar1)*(ratingDict[(u,i2)] - iBar2)\n",
    "        \n",
    "    # denominator in terms of shared items\n",
    "    for u in inter: \n",
    "        denom1 += (ratingDict[(u,i1)] - iBar1)**2\n",
    "        denom2 += (ratingDict[(u,i2)] - iBar2)**2\n",
    "    denom = math.sqrt(denom1) * math.sqrt(denom2)\n",
    "    if denom == 0: return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilarItem_by_pearson1(i, N):\n",
    "    similarities = []\n",
    "    users = usersPerItem[i]\n",
    "    for i2 in usersPerItem:\n",
    "        if i2 == i: \n",
    "            continue\n",
    "        sim = Pearson1(i, i2) # Could use alternate similarity metrics straightforwardly\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(key=lambda tup: (-tup[0], tup[1]))\n",
    "    return similarities[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0000000000000002, '1103951'),\n",
       " (1.0000000000000002, '11986350'),\n",
       " (1.0000000000000002, '16007365'),\n",
       " (1.0000000000000002, '17132269'),\n",
       " (1.0000000000000002, '17571519'),\n",
       " (1.0000000000000002, '18468852'),\n",
       " (1.0000000000000002, '18527488'),\n",
       " (1.0000000000000002, '18594657'),\n",
       " (1.0000000000000002, '18624024'),\n",
       " (1.0000000000000002, '1882498')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3(a) answer\n",
    "mostSimilarItem_by_pearson1(i1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Pearson similarity with denominator in terms of all items each user consumed (i.e., Ui or Uj for each term in the denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pearson2(i1, i2):\n",
    "    # Between two items\n",
    "    iBar1 = itemAverages[i1]\n",
    "    iBar2 = itemAverages[i2]\n",
    "    # intersection of users that have rated items i and j\n",
    "    inter = usersPerItem[i1].intersection(usersPerItem[i2])\n",
    "    numer = 0\n",
    "    denom1 = 0\n",
    "    denom2 = 0\n",
    "    \n",
    "    # numerator is the intersection of users\n",
    "    for u in inter:\n",
    "        numer += (ratingDict[(u,i1)] - iBar1)*(ratingDict[(u,i2)] - iBar2)\n",
    "        \n",
    "    # denominator in terms of all items each user consumed\n",
    "    for u in usersPerItem[i1]:\n",
    "        denom1 += (ratingDict[(u,i1)] - iBar1)**2\n",
    "    for u in usersPerItem[i2]:\n",
    "        denom2 += (ratingDict[(u,i2)] - iBar2)**2\n",
    "    denom = math.sqrt(denom1) * math.sqrt(denom2)\n",
    "    if denom == 0: return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilarItem_by_pearson2(i, N):\n",
    "    similarities = []\n",
    "    users = usersPerItem[i]\n",
    "    for i2 in usersPerItem:\n",
    "        if i2 == i: \n",
    "            continue\n",
    "        sim = Pearson2(i, i2) # Could use alternate similarity metrics straightforwardly\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(key=lambda tup: (-tup[0], tup[1]))\n",
    "    return similarities[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.31898549007874194, '20300526'),\n",
       " (0.18785865431369264, '13280885'),\n",
       " (0.17896391275176457, '18208501'),\n",
       " (0.16269036695641687, '21521612'),\n",
       " (0.16269036695641687, '25430791'),\n",
       " (0.1555075595594449, '1341758'),\n",
       " (0.1526351566298752, '6314737'),\n",
       " (0.15204888048160353, '4009034'),\n",
       " (0.1494406444160154, '988744'),\n",
       " (0.14632419481281994, '18430205')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3(b) answer\n",
    "mostSimilarItem_by_pearson2(i1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    user,item = d['user_id'], d['book_id']\n",
    "    reviewsPerUser[user].append(d)\n",
    "    reviewsPerItem[item].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.778138356523054"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingMean = sum([d['rating'] for d in data]) / len(data)\n",
    "ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRating(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['book_id']\n",
    "        if i2 == item: continue\n",
    "        ratings.append(d['rating'] - itemAverages[i2])\n",
    "        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        return ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_of_rating_prediction(predict, rating):\n",
    "    SE = [(a-b)**2 for a,b in zip(predict, rating)]\n",
    "    return sum(SE) / len(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy: Since it takes too long to run on the whole dataset, I instead make predictions on a random subset of size 10,000 without the loss of generality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract subset of data with size 10000\n",
    "sample = random.sample(data, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the sample\n",
    "predictions = [predictRating(d['user_id'], d['book_id']) for d in sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = [d['rating'] for d in sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8363993189608434"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4 answer\n",
    "# compute MSE on sample\n",
    "MSE_of_rating_prediction(predictions, ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Modify the similarity function from Question 4 to use the cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cosine(i1, i2):\n",
    "    # Between two items\n",
    "    inter = usersPerItem[i1].intersection(usersPerItem[i2])\n",
    "    numer = 0\n",
    "    denom1 = 0\n",
    "    denom2 = 0\n",
    "    for u in inter:\n",
    "        numer += ratingDict[(u,i1)]*ratingDict[(u,i2)]\n",
    "    for u in usersPerItem[i1]:\n",
    "        denom1 += ratingDict[(u,i1)]**2\n",
    "    for u in usersPerItem[i2]:\n",
    "        denom2 += ratingDict[(u,i2)]**2\n",
    "    denom = math.sqrt(denom1) * math.sqrt(denom2)\n",
    "    if denom == 0: return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRatingWithCos(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['book_id']\n",
    "        if i2 == item: \n",
    "            continue\n",
    "        ratings.append(d['rating'] - itemAverages[i2])\n",
    "        similarities.append(Cosine(item,i2))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        return ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the sample\n",
    "predictions = [predictRatingWithCos(d['user_id'], d['book_id']) for d in sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8356020751105451"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5(a) answer\n",
    "# compute MSE on sample\n",
    "MSE_of_rating_prediction(predictions, ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Modify the similarity function from Question 4 to use the two definitions of Pearson similarity from Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRatingWithPearson1(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['book_id']\n",
    "        if i2 == item: \n",
    "            continue\n",
    "        ratings.append(d['rating'] - itemAverages[i2])\n",
    "        similarities.append(Pearson1(item,i2))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        return ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the sample\n",
    "predictions = [predictRatingWithPearson1(d['user_id'], d['book_id']) for d in sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.406678744237735e+24"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5(b)-1 answer\n",
    "# compute MSE on sample\n",
    "MSE_of_rating_prediction(predictions, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRatingWithPearson2(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        i2 = d['book_id']\n",
    "        if i2 == item: \n",
    "            continue\n",
    "        ratings.append(d['rating'] - itemAverages[i2])\n",
    "        similarities.append(Pearson2(item,i2))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        return ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the sample\n",
    "predictions = [predictRatingWithPearson2(d['user_id'], d['book_id']) for d in sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1615.1700734159913"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5(b)-2 answer\n",
    "# compute MSE on sample\n",
    "MSE_of_rating_prediction(predictions, ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Modify the similarity function from Question 4 to use the  Jaccard similarity, but interchanging users and items (i.e., in terms of the similarity between users Sim(u, v) rather than Sim(i, j))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRatingSimUser(user,item):\n",
    "    ratings = []\n",
    "    similarities = []\n",
    "    for d in reviewsPerUser[user]:\n",
    "        u2 = d['user_id']\n",
    "        if u2 == user:\n",
    "            continue\n",
    "        ratings.append(d['rating'] - userAverages[u2])\n",
    "        # in terms of the similarity between users Sim(u, v)\n",
    "        similarities.append(Jaccard(itemsPerUser[user],itemsPerUser[u2]))\n",
    "    if (sum(similarities) > 0):\n",
    "        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]\n",
    "        return itemAverages[item] + sum(weightedRatings) / sum(similarities)\n",
    "    else:\n",
    "        # User hasn't rated any similar items\n",
    "        return ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the sample\n",
    "predictions = [predictRatingSimUser(d['user_id'], d['book_id']) for d in sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3361374533772217"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5(c) answer\n",
    "# compute MSE on sample\n",
    "MSE_of_rating_prediction(predictions, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
